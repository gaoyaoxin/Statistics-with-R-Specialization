{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Visualizing-Numerical-Data\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Visualizing Numerical Data</a></div><div class=\"lev1\"><a href=\"#Measures-of-Center\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Measures of Center</a></div><div class=\"lev1\"><a href=\"#Measures-of-Spread\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Measures of Spread</a></div><div class=\"lev2\"><a href=\"#variance\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>variance</a></div><div class=\"lev2\"><a href=\"#standard-deviation\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>standard deviation</a></div><div class=\"lev2\"><a href=\"#variability-vs-diversity\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>variability vs diversity</a></div><div class=\"lev2\"><a href=\"#interquatile-range-(IQR)\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>interquatile range (IQR)</a></div><div class=\"lev1\"><a href=\"#Robust-Statistics\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Robust Statistics</a></div><div class=\"lev1\"><a href=\"#Transforming-data\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Transforming data</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-17 at 8.33.01 AM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/9kRJf/visualizing-numerical-data) 7:14*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-17 at 8.37.41 AM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/9kRJf/visualizing-numerical-data) 9:28*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-17 at 8.39.19 AM.png\">\n",
    "<img src=\"images/Screen Shot 2016-05-17 at 8.39.26 AM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/9kRJf/visualizing-numerical-data) 10:06*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-17 at 8.50.01 AM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/AM0o6/measures-of-center) 4:19*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Measures of Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.20.21 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 2:22*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.29.18 PM.png\">\n",
    "<img src=\"images/Screen Shot 2016-05-27 at 7.29.29 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 3:51*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variability vs diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.31.32 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 4:27*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.32.47 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 4:58*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "- This time, the answer is actually Set 2. Remember, distributions where more observations are clustered around the center, are less variable, versus distributions where more observations are away from the center, are more variable.\n",
    "- We can take a look at dot plots of these distributions, to make that point a little more clear. In the first set, the average gas mileage is 30 miles per gallon, and the values range from ten to 50, but there is one observation at the mean and two others closer to the mean than the endpoints. In the second, the set, the average gas mileage is 26 miles per gallon and the values also range from ten to 50. But there are no observations at or near the mean. Therefore, the average deviation from the mean, is higher for this set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.34.42 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 5:37*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interquatile range (IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.36.55 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 6:56*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.38.31 PM.png\">\n",
    "<img src=\"images/Screen Shot 2016-05-27 at 7.38.42 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/t9Wbk/measures-of-spread) 6:56*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We define robust statistics as measures on which extreme observations have little effect.\n",
    "- Let's give a quick example. We start with a small data set of values between one and six, and the mean and the median for these data are both 3.5. What if we change one of the values in the data set to be much larger? Say 1000. The mean increases greatly, but the median stays the same at 3.5. In other words, the mean is robust to the extreme observation. This is because while the mean depends on all observations in the data set, it is the arithmetic average, after all. The median only depends on the midpoint of the distribution and the values of the end point are irrelevant to its calculation. We just established that the median is a more robust statistic of center than the mean. \n",
    "- Going along with this the IQR, which is based on the median, is a more robust statistic than the standard deviation which is calculated using the mean. As well as range which relies solely on the most extreme observations. \n",
    "- Robust statistics are most useful for describing skewed distributions, or those with extreme observations. While non-robust statistics like mean and standard deviation are useful for describing symmetric distributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.43.50 PM.png\">\n",
    "<img src=\"images/Screen Shot 2016-05-27 at 7.44.49 PM.png\">\n",
    "<img src=\"images/Screen Shot 2016-05-27 at 7.44.59 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/ssktR/robust-statistics) 1:25*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.46.12 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/eQa2U/transforming-data) 0:40*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most commonly used transformation is the **natural log transformation**, which is often applied when much of the data cluster near zero relative to larger values in the dataset and all observations are positive. For example, we saw earlier that the distributions of income per person was heavily right skewed. But after applying a natural log transformation, the data become much more symmetric. Sometimes this type of data are much easier to model, because they are much less skewed and outliers are usually less extreme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.47.34 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/eQa2U/transforming-data) 0:57*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformations can also be applied to one or both variables in a scatter plot to make the relationship between the variables more linear. And hence, easier to model with simple methods. \n",
    "- For example, here we have a scatter plot of income per person versus life expectation. The relationship is positive and curved. If we apply a log transformation to the response variable and then plot the relationship again, the relationship stays positive, but becomes more linear, which makes it easier to model than the untransformed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.49.38 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/eQa2U/transforming-data) 1:23*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformations other than the logarithm can be useful too. \n",
    "- Let's take a look at a new dataset. Here, we have a scatter plot of a random sample of cars weight versus their city mileage. We can see that the two variables are inversely related, which is expected. Cars that are bigger get fewer gallons to the mile, but the relationship is not linear. In addition to the log, we can also try a square root transformation where we plot the square root of the weight versus miles per gallon or the inverse transformation where we divide one by the weight of the car. It's difficult to tell just looking at these plots which transformation works better or if either of the transformation actually yield something better than the original data. \n",
    "- Later in the course, we'll get into a little more detail about how to make such a call. But for now, it's important to just realize that transformations can be useful even though they complicate the interpretations a bit. After all, log of income or the square root of weight are not easy to evaluate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.52.02 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/eQa2U/transforming-data) 2:04*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-27 at 7.53.53 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/eQa2U/transforming-data) 2:59*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": "8",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
